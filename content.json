{"pages":[],"posts":[{"title":"検出方向とエッジ方向","text":"XG-Xのエッジ位置計測ユニットのエッジ位置検出では、濃度の絶対値ではなく、エッジを検出する方向に対して垂直方向に、計測領域内の投影処理を実行した結果による平均濃度の変化量によって求まります。この変化量のことを「エッジ強度」と呼びます。つまり、相対的に変化量の多い部分付近に強度グラフのピークが現れ、逆に変化量に乏しく平坦性のある領域はグラフが沈んでいくことになるので、実際の観察画像と強度を表すグラフの相関が非常にわかりやすい形で示されます。 計測領域が矩形の場合、検出条件でまず設定すべきポイントは検出方向とエッジ方向で、検出方向で画面に向かって右側にスキャンするのか？左側にスキャンするのか？を選択する必要があります。仮に右側に向かって検出方向を設定した場合、領域内を右側に向かってスキャンされますが、このとき検出したいエッジの変化を観察してエッジ方向を設定します。エッジ方向で設定すべきパラメータは、暗い部分から明るい部分に変化する場合、逆に明るい部分から暗い部分に変化する場合、あるいは、その両方を含むのか？によって3種類の設定が可能ですが、はじめの暗い部分から明るい部分に向けての方向を選択した場合は、あるエッジが存在したとして、その境界を境に左側が暗く、右側が明るいエッジを検出することになります。逆に明るい部分から暗い部分に向けての変化をとりたいのであれば、2番目の選択肢である明るい部分から暗い部分へのパラメータを設定します。そして3番目の両方を選択可能な設定にした場合は、変化の方向は考慮することなくエッジを検出したすべてのポイントが強度グラフのピークになって表現されます。 今度は、計測領域が円弧や円周状の領域の場合ですが、検出方向の設定パラメータは矩形領域の場合とは違い、円周状の方向で決めることになります。スキャンの方向が時計回りであれば右側として設定し、逆に反時計回りであれば左方向への検出方向という表現になります。エッジ方向の考え方自体は計測領域が矩形の場合と同じように、暗いから部分から明るい部分への変化なのか？逆に明るい部分から暗い部分への変化のか？あるいはその両方を検出したいのか？ということになります。また、計測領域が円周の場合はエッジスキャンを開始する角度を決めることが出来ます。ちょうど変化の方向が円周状をトレースして元に戻る形になるので、矩形を選択した場合とは異なり、開始位置を示さないと目的と達成できない場合があるからです。理由は、計測領域が矩形の場合は、スキャンしたいエリアを包括的に設定しますが、つまり、開始位置と終了位置と大きさがおのずと決まるのに対して円周状の場合は、1周してしまうので開始地点と終了始点がわからないので不便なことが起こり得ます。具体的には、スキャンをはじめたポイントに検出したいエッジが偶然存在した場合、そのエッジを探し当てることはできません。したがって、計測領域が円周状の場合は、開始角度を設定して、それも、さきの偶然がなるべく発生しないポイントを角度で示してあげる必要があります。ここで注意が必要ですが、角度0度になるのは、時計で言うと3時の方向になります。したがって、真下方向、時計で言えば6時の方向からスキャンを開始したい場合は、開始角度に 90 を設定することになります。 では、検出されたポイントがいくつか存在し、その中から任意の検出ポイントを選びたい場合はどうするのでしょうか？複数のポイントが検出された場合は、判定ラベルというのが自動的に振られ任意の番号を指定することにより本当に検出したいポイントを選び出すことが可能です。たとえば、画面に向かって左側から右側に向けて検出方向を設定したとします。複数の検出ポイントを見つけましたが、本当に欲しい検出ポイントは左側から2番目のエッジだったとします。その場合、判定ラベルで示すのは「1」です。したがって、判定ラベル1を設定することにより、左から2番目のエッジを検出できることになります。 Regards;","link":"/blogger/2019/05/17/2019-05-3rdweek/"},{"title":"多段位置補正の方法","text":"今回はXG-Xの VisionEditor を使った多段位置補正の実例を紹介したいと思います。多段位置補正というのは、複数の画像に対してX軸方向とY軸方向にズレがあるような場合、補正をした後にいろいろな処理や計測をしたい場合に用いられる基本的な構成回路です。 では、まず下記のような2枚の画があると想定します。 画像Aと画像Bでは微妙にX軸方向とY方向がズレていることがわかると思います。この2つの画から、双方のドリンクの取り出し口の内寸のサイズを計測したいと思いますが、当然ながら2つの画像は位置がずれているのでうまく計測することが出来ません。そこで、2つの画像のうちどちらかにおいて基準の位置を決めてやり、もう一方の画像を合わせてあげることができれば、2つの画像の位置は同じ場所になります。これは多数の画像がある場合も同様で、いろいろな方向にズレている場合は、ひとつの基準を決めてやり、その位置に画像を合わせこむことにより常に補正された位置での計測が可能になります。 ここでは画像Aを基準位置としてリファレンスの役割を持たせます。 最終的に、このように2つの画像のドリンクの取り出し口の内寸をズレることなく計測できればOKです。 今回のX軸方向を優先した多段補正のユニットの構成は、下記、図4のようになります。 それでは、ひとつづつ確認したいと思いますが、画像は使用するカメラの解像度に合わせたものであれば、なんでも構いません。その画像を（今回は画像Aのほうをリファレンスとします）画像登録します。はじめに画像Aを利用したX軸の基準線を決めるために エッジ位置ユニット を利用して検出条件を 図5 のように設定します。領域設定は「矩形」を設定して領域を決めますが、このときのポイントとして未知の画像がどのくらいズレていても許容できるかを考慮しないとなりません。つまり、リファレンスの画像に対してエッジ（この場合X軸）を決めているラインに、未知の画像のラインが収まらないと同じX軸で位置補正することができなくなってしまいます。「検出方向」や「エッジ方向」は使用する画像により設定値がかわると思いますので適宜調整してください。 つづいて、位置補正ユニット を組み込みます。このときのポイントは、「参照先設定」の「検出位置指定 1点目」で、位置補正に利用する対象となるユニットを選択します。つまり、ここではX軸の基準線を決めた エッジ位置ユニット を参照することになります。これにより、この位置補正ユニットは、X軸の基準線を利用して未知の画像の同じラインを持つエッジを補正することになります。もうひとつ忘れてはならないことは、「基準位置指定方法」のプルダウンメニューで「現在値登録」を選択して、「基準位置登録」ボタンを押します。 次に、Y軸の補正回路を構成しますが、基本的な考え方はX軸と同じで、図7に示すように Y軸方向のエッジを検出するための エッジ位置ユニット を組み込んで領域設定を注意深く決めたらY軸方向のエッジを検出します。ただ、ここでひとつ注意すべきポイントは、Y軸の補正は、本来はY軸方向のみを補正するはずですが、X軸方向の補正ユニット（位置補正ユニット）からX軸方向の補正量を引き継いでいるため、これから組み込むY軸方向の「位置補正ユニット」に対して、XY方向の補正量を引き継ぐことになります。このときの設定が、「領域設定」タブの「位置補正元ユニットID」の項目で、さきほど設定した位置補正ユニットを選択して参照する必要があります。 そして、Y軸に対する 位置補正ユニット を組み込みます。X軸に対する位置補正と考え方は同じで、今度は補正元の参照先は 図7で設定した エッジ位置ユニット を選択します。同じように現在位置で基準位置登録をするのがポイントになります。 ここまででX軸方向とY軸方向への多段位置補正の回路の構成を完了しました。では、最後にドリンクの取り出し口の内寸を計測する エッジ幅ユニット を組み込んで位置補正した画像を正しく計測するかを確認します。（図9） 結果は下記のとおりです。画像Aの計測結果は 図10。そして画像Bの計測結果が 図11 です。ズレを補足しつつドリンクの取り出し口の横幅の内寸を測定しているのがわかると思います。 当然ながら、多段位置補正は回路を構成する補正ユニットに対して違う画像の情報を与えてしまってはうまく位置補正することが出来ません。必ずリファレンス画像は同じものする必要があります。 今回はここまで。 今週気になったニュースMicrosoft .NET Core 3.0 の後継 .NET 5 2020年にリリースついにここまで来たか！と同時に、やっと整理されたか！ なのか … これはインパクトのある発表です。.NET5は、Windows, Linux, iOS, Android の枠を超えた単一プラットホームを目指しています。というのは今に始まったことではないが、現状の .NET Core, .NET Framework, Xamarin/Mono のNETファミリーがやっと大きな1本の木になるようです。で、中身はなんなのか？ と言うと … ワンコードでの管理 Objective-C, Swiftもサポート Javaとの互換性 Jitの強化 … などなど。プレビューリリースは来年前半、正式リリースは秋。毎年11月にメジャーバージョンがリリースされ、偶数バージョンがLTSになるとのこと。 Best Regards; endo.kenichi@aesoftlab.co.jp","link":"/blogger/2019/05/24/2019-05-4thweek/"},{"title":"ブログを開設","text":"ブログを開設。 モチベーション ここでは、日々蓄積される（本当に蓄積されるはずだ！）ナレッジやデータを書き留めるための、一種の備忘録、あるいは、記録として機能することになる。したがって、出来るだけサクサク書くことが出来ることが望ましい。もっと言えば、体裁の細かな微調整などに余計な神経をもっていかれたくない .. という思惑があって、もちろん、デザイン的な観点で言えば、そういうわけにもいかないことは重々理解をしている。 そうではなく、より本質にスコープしてここの記事を書いていくということが大きな目的でもある。そういうわけで、ストレスフリーにさらっと書き進めるためには、現状では Markdown 一択という選択から始めた。 いまは、CMSも多岐に渡り、高機能の恩恵を受けることが可能だが、本当は、もっとシンプルに簡単に意見を発信できれば、もっと便利なはずだ。そこで、そもそも静的なサイト（データそのもの）を記述することが出来れば、目的と合致する。 実際、世の中はある意味では原点回帰のようなことも起こっている。Wordpress や Drupal のようなかなり優秀なCMSでサイトを運営する方向と、インターネット黎明期のような静的サイトへの回帰。後者は非常におもしろい分野へと変化してきている。これは、ある意味、Jam Stack分野への回帰としても捉えることが出来るだろう。たとえば、データベースがバックエンドに存在しなければ、そもそもセキュリティ面でのアドバンテージを稼ぐことが、非常にシンプルになり得る。同時に、更新の手間暇の煩雑さからの開放という点でも大きな効果が得られる。という動機付けのもとに、この備忘録は、Hexoというパッケージでサイトを構築し、その結果をGithubでホストしている。ブログは、Githubの中の GitPages でホストされるというしくみをとっている。 執筆環境は Visual Studio Code から、HexoパッケージをインストールしたLinuxサーバへSSHで接続してMarkdownを快適に書き進めることが出来るようなイメージ。 プラットホーム自体は、Node.js があれば、さくっと立ち上がるものでもあるが、そのしくみも含めて構築手順書的な観点で、あるいは、備忘録という意味で、本サイトを公開するまでの流れを書いておく。 Quick Start1、hexo環境の構築 すでにNode環境があれば別だが、今回は Docker でオートメーションを達成したい。あるいは、地道に環境を構築してもまったく構わない。その際、OSは Windows, Mac, Linux を問わない。Nodeの実行環境が手に入ればプラットホームは問わない。 以下に、Dockerfile の内容を示す。 1234567891011121314151617181920212223242526272829303132333435363738394041FROM ubuntu:16.04# proxy ここは必要に応じて#ENV https_proxy=\"http://name:password@proxy:8080/\"#ENV http_proxy=\"http://name:password@proxy:8080/\"# OpenSSHRUN apt-get update &amp;&amp; apt-get install -y \\ openssh-serverRUN mkdir /var/run/sshdRUN echo 'root:root' | chpasswdRUN sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config# SSH ログインRUN sed 's@session\\s*required\\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshdENV NOTVISIBLE \"in users profile\"RUN echo \"export VISIBLE=now\" &gt;&gt; /etc/profile# 一般ユーザを作成して、Node.jsのリポジトリからステーブルを選択してインストールRUN apt-get install -y git less vim sudoRUN apt-get install -y nodejs npmRUN npm install n -gRUN n stableRUN apt purge -y nodejs npmRUN n 11.2.0RUN useradd -m aandeRUN echo 'aande:aande' | chpasswdRUN usermod -aG sudo aandeRUN chsh -s /bin/bash aande# HexoRUN npm install -g \\ hexo-cliRUN npm install \\ hexo-deployer-git --save \\ hexo-admin --save# SSH、Webサーバ、Adminサーバ公開用のポートEXPOSE 22 4000 8080CMD [\"/usr/sbin/sshd\", \"-D\"] 今回は、OSに Ubuntu16.04 を指定した。簡単に解説を加えると、はじめのレイヤーでOpenSSHのインストールとroot権限を設定している。 Dockerの特性として何層かのレイヤーでビルドを積むことにあるので、細かく（あまり細かすぎても、あるいは、薄すぎても別の弊害を生みが …）層を重ねることによりビルド時間の短縮効果を得ることが出来る。次に、Node.jsをセットアップしている。ここでインストールしている Node.js, npm の目的は、パッケージマネージャを通じて n package を導入することにある。Windowsで言えば nodist のような役割で、これによりどのバージョンの Node.js をインストールして使用するか、を選択可能としている。 事前の調査で現在の Node.js の Stable/LTS を確認して、バージョンを選択してインストールしている。ここまでのコードの実行後は、目的の Node.js がインストールされたので、事前にインストールした（つまり、n package を導入することを目的とした）バージョンは削除している。もちろん削除しなくても構わない。とくに環境汚染（実際に汚染があるわけではないが）の類の問題に関してナーバスな方は、きれいしに整理したほうがよいことは言うまでもない。 ここで、n package の説明を簡単に。別のバージョンの Node.js のインストール、管理がシンプルになるので、そういった目的の場合は、以下のコマンドを実行する。 1234567891011$ sudo n 10.12.0$ node -vv10.12.0# 上記のコマンド実行により、バージョン 10.12.0 に切り替わった。 # また、エイリアスも使用できる。# 下記は、LTSの選択。$ sudo n lts$ node -vv10.15.3 さて、話が横道に逸れてしまったが、元に戻す。次に一般ユーザの設定をして、次が本筋の Hexo のインストール。hexo-cli をグローバルインストールをして、続いて Githubデプロイ用に必要な hexo-deployer-git をインストールしている。もちろん、gitコマンドでデプロイ（というか、Push）するのであれば、それでも構わない。次にセットアップする hexo-admin は、ブログの作成をブラウザ上から実行出来るようにするための、いわゆるダッシュボードのようなもので、無理にインストールする必要はない。今回も、記事の作成は、Visual Studio Code でサクサク … というのが主目的なので、使用する予定はない。ただ、一応、関連パッケージということで紹介をしてみた。 最後にポートを export しているが、これは言うまでもなく、SSH用に22番、ブログ表示を4000番（つまり、デバッグ用の … というか、ローカル表示確認用のWebサーバ役と、前段で説明したダッシュボード表示のために8080番を開けている。Dockerfileに関する説明は以上。 次いで、上記の Dockerfile に基づいて、Dockerイメージをビルドする。イメージの名前は任意。 1$ docker build -t ssh-node-sandbox:latest . 出来上がったイメージからコンテナを生成する。 123$ docker run -d \\ -p 20022:22 -p 4000:4000 -p 8080:8080 \\ --name ssh-hexo-blogger ssh-node-sandbox これで dockerコンテナが起動した。実行されているか見てみよう。 123$ docker psb3436e362b47 ssh-node-sandbox &quot;/usr/sbin/sshd -D&quot; 26 hours ago Up 2 hours 0.0.0.0:4000-&gt;4000/tcp, 0.0.0.0:8080-&gt;8080/tcp, 0.0.0.0:20022-&gt;22/tcp ssh-hexo-blogger OK！ では、さっそくコンテナにSSHで入ってブログサイトを構築してみるが、その前に Visual Studio Code にSSHの拡張プラグインをセットアップする。もちろん、ほかのSSHクライアントで接続してLinux上のVimなどのエディタを使用しても構わないが、ここは、Visual Studio Code の快適さを選択したい。選択したのは SSH FS を使用する。 2、ブログサイトの構築コンテナに入ったら、以下の手続きでブログサイトを構築する。 12345678910# 任意のディレクトリに移動して、そこをワークスペースとする。# ここから Hexoコマンドを実行して、ブログサイトを構築する。$ hexo init blog# 最後の blog がサイト名となる。もちろん任意でOK。# 作成したサイト用ディレクトリに移動する。$ cd blog# ここで、ディレクトリ内のオーダーを見ると package.json があるはずなので、その中にリストされているライブラリを導入する。やり方は簡単だ。以下の1行のコマンドを実行するのみ。$ npm install これで、ブログサイトの雛形が展開された。さっそく記事を書いてみる。 3、記事の作成1$ hexo new &quot;記事の名前&quot; 上の記事の名前は任意。ページのテンプレートが作成されたので、おもむろに記事を書く。記事を書き上げたら、以下のコマンドでサーバを起動する。 1$ hexo server これで、ローカル環境で書いた記事を確認出来る。ブラウザで localhost:4000 にアクセスする。いま、書き上げた記事が表示されるはずだ。dockerのホストに docker-machine を使用している場合は、おそらく、192.168.99.100:4000 のようなアドレスになるはずなので、ここはケアレスミスのポイント。慌てずに確認。この部分は、dockerのホストが何であれ、WindowsもMac, あるいは Linux でも変わりはない。 どうだろうか？これで簡単にブログサイトを、ローカル環境ではあるが構築出来てしまった。これだけでも簡単に目的が達成できたことが実感出来るだろう。しかし、ここまでが前段で、残りのデプロイがある。 4、デプロイ最後のプロセスまで辿り着いた。まずは、以下のコマンドを初期に覚えておくとよいかもしれない。 はじめは、以下の generate コマンド。 123$ hexo generate# または$ hexo g これは公開用のリソースを、asset も含めて publicフォルダ に生成するためのコマンド。 つまり、HTMLコードや公開に必要な画像などのファイル群、あるいは css なども含めて、出力される。このHexoソリューションのディレクトリ構成を見ると、いま作成中のドキュメントは source 配下のサブフォルダに存在するはずだ。このソースがビルドされた後、publicフォルダに公開用の静的セットとして生成されるというしくみだ。上記の generate コマンドの実行をすると、コンソールにその結果が出力されるので確認は容易だ。 さて、最後のコマンド。deploy。 123$ hexo deploy# または$ hexo d 今回想定している Github リポジトリに公開用ファイルがデプロイされる。そして、Github の当該リポジトリにアクセスをして、Settingsタブを選択する。その後、画面を下のほうにスクロールして、Github Pages の項目を見つければ、そこにたったいまデプロイしたブログのURLが設定されている。そこをクリックすると、結果を表示出来る。これですべてが完了だ。 ここまでの作業を長々と説明を加えてきたが、手順をしっかり踏めば、おそらく10分程度でサイト公開までは辿り着けるはずだ。もちろん記事を書く時間は除外する。つまり、記事を書くのが本質であって、それ以外にはなるべくサクッとすませたいというのが今回の狙いでした。 Best Regards; 今週気になったニュース■ PLCの未来像を描く「PLCnext」、用途別アプリなどを順調に拡大 - ハノーバーメッセ2019ラダー言語を用いることが多い PLC だが、Visual Studio、Eclipse、MATLAB/Simulink、PC Worx Engineerなどのツールの活用に加え、C#などの活用も進みそうだ。かつ、オープンプラットフォームで制御領域の拡大にも一気に貢献しそうな気配でもある。","link":"/blogger/2019/04/20/2019-04-3rdweek/"},{"title":"Jupyter notebook のインストール","text":"近年、python が基軸言語 … とまでは言わないが、その重要性は確固たる地位を築きつつあるのと同時に、興味は持っているが、あるいは、始めてみたいとは思っているが、なかなか手がつけられないという相談をあちこちで受ける機会が多くなってきた。 そういうわけで今回は、python を手軽に試してみたい、という向きに、python の環境構築の方法を紹介したい。それも出来るだけシンプルに手軽に、というポイントに絞り記事を書いてみたいと思う。と言うのも、python の処理系を構築するには、ネットで調べてみると、多くの情報を集めることが出来るが、あまりにも多くの情報が見つかり、体系的に整理するのが逆に困難であることが災いして手軽に試すということから遠ざかってしまう場合が多いように思われるからだ。 たとえば、まず python の最新版をインストールした後、virtualenv を導入して、目的のバージョンの python を個別にインストールして仮想ディレクトリに封じ込めて環境汚染を防ぐ … というような記事をそのままトレースしようとすると、また今度にしよう、と考えるのも無理はないと思う。なので、たったいまここで書いた内容は、一度頭の中から除去して、とにかく python のコードを何行か書いて（それも即時性のある、意味のある、手軽に目的を達成するような）試すことができる記事を目指したいと思う。 まずは、ここで python をインストールするための方針を固める。anacondaパッケージを導入して、pythonの処理系をインストールした後、jupyter notebook で python のコードを実行する、という方針で進めたい。 今回のゴール python の実行環境である Anaconda のインストール jupyter notebook で python のコードを実行 さて、ここまで読んでいただいて、はて？ python のインストールという文脈で、jupyter notebook とは、いったい何なんだ？ という疑問を持たれた方も、当然多いと思う。ここだけは、ひとまずガマンして頂いて、python をインストールするにあたって、jupyter notebook というものが出てくるのか・・ 程度に理解してもらえれば充分だ。強いて言えば、python を実行するためのインタープリタを持つツールという位置づけで理解してもらえればよいと思う。とにかく python のコードを実行した後、理屈を理解していけば入り口としては単純だ。 今回は最もシンプルに試すために、python環境を構築するOSとして Windows を想定する。 早速 ここにアクセスして 画面右上にある Download をクリックする 画面中間部にあるWindowsのアイコンをクリックする 画面下にたどって、Python 3.7 Version Download と書かれた下に、64-Bit、または、32-Bitの都合の良い方のインストーラをダウンロードする これで、pythonの動作環境のインストーラが手に入ったはずだ。少し解説を加えておく。たったいまダウンロードしたインストーラは、pythonの動作環境に加えて、さまざまなライブラリ、ツールを含んだ anaconda と呼ばれるパッケージのインストーラを手に入れたことになる。詳しくは省略するが、これをOS上に展開することにより、pythonの具体的、かつ、興味深い一面をいとも簡単に実行に移すことが可能になる。 では、インストーラをダブルクリックしてインストールしてみよう。 2019年3月現在の最新バージョンであることがわかる。Next をクリックして次に進もう。 ライセンス条項を確認して I Agree をクリック。 クレデンシャルの設定だが、自分だけで構わないと思われるので、Just Me をチェックして Next をクリック。 インストールするディレクトリは任意で構わない。値を設定したら、Next をクリック。 ここは、Register Anaconda as my default Python 3.7 のほうにチェックを入れて、Install をクリック。ここでインストールが始まるので、その間にコーヒーでも淹れてリラックス。 さて、インストールが完了したら … Quick Startコマンドプロンプトを起動して、以下のコマンドを入力後 Enter をヒット。 &gt; jupyter notebook その後、ブラウザで http://localhost:8888 にアクセス。これで、jupyter notebook が起動した。これでひとつのハードルは越えた。おめでとう。 次に、画面右側にある New というプルダウンメニューが見えると思う。そこを選択して、表示されたメニューの中から Python 3 を選択すると、notebook が表示されると思う。まさにこれが、これから python のコードを実行するにあたりさまざまなコードを入力するノートブックだと思って欲しい。jupyter notebook は、pythonコードの実行を、このようにあたかもノートブックに記録するように保存し、ロードし、頭の中の試行錯誤を具現化するための抽象インターフェースだと考えればいいと思う。 使い方だが、簡単な説明だけを書く。In [ ]: の右側に細長いボックスがあるが、これがセルと呼ばれる項目だ。この部分にコードを入力して実行すると Out[ ]： という形で結果が得られる。それだけだ。どうだろう。簡単じゃないか。ひとつ簡単な例で試してみよう。In[ ]: の右側のセルに、次のようなコードを入力して、Shiftキーを押しながら Enter をヒットしてみよう。 In [ ]: x = 2 x * 2 Out [ ]: 4 上のような結果が得られれば OK。これは、つまり、x という名前の変数を用意して 2 を代入している。次に、x * 2 を実行する。その結果 4 が得られた。これで、python のコードが実行されたことになる。素晴らしい！しかし、これでは、あまり実用的ではないし掘り下げていくにはあまりにも単純すぎる。そこで、次はもう少し実用的で、かつ、高度でありながら python らしいシンプルな解法を試してみることにする。それでは、例を下に示すが、サンプルコードを実行するにあたり、少し辛抱して、下記のコマンドを実行して欲しい。なお、コマンドの実行にあたり、コマンドプロンプトをもうひとつ新たに立ち上げて実行すること。なぜなら、さきほど jupyter notebook を起動したDOSプロンプトはフォアグラウンドでpythonのプロセスが実行されているからだ。jupyter notebook のログが出力されているのが観察出来ると思う。したがって、別のコマンドプロンプトを起動して下記のコマンドを実行して欲しい。実行するディレクトリは任意で構わない。 &gt; pip install pandas-datareader いまの段階ではこのコマンドの意味をわからなくても構わないので、とにかく実行してエラーがなく終了することを確認する。ちなみに、いま実行したコマンドは python の処理系に pandas-datareader というライブラリを導入する役割を実行したことになる。では、pandas-datareader とは何か？ と言うと、簡単に言えば日経平均株価を取得するものだ。 次に、コード例を示す。さきほどと同じように、jupyter notebook 上で、新しいノートを新規作成して入力する。やり方は、New というプルダウンメニューで Python 3 を選択する。すると新しいノートが作成されるので、In [ ]: の右側にあるセルに次のコードを入力する。 In [ ]: import datetime import requests import pandas as pd import matplotlib.pyplot as plt %matplotlib inline import pandas_datareader.data as web 上記のコードの意味は、これから実行するコードのライブラリをimportすることにある。いちばん下のコードが、さきほど導入した pandas-datareader をimportしているコードで、その他は anacondaパッケージ に備わっている標準ライブラリをimportしているコードだ。ここまで入力したら、Shiftキーを押しながら Enterキーをヒット。続いて … In [ ]: start = datetime.datetime(1970, 1, 4) end = datetime.datetime(2019, 4, 26) # 必要に応じて設定 InsecureRequestWarning session = requests.Session() session.verify = False df = web.DataReader(\"^N225\", \"yahoo\", start, end, session=session) 上記のコードは、日経平均株価のデータを取得しているが、当該セクション冒頭で1970年1月4日から今年の4月26日までのデータを取得する設定をしている。 In [ ]: # indexを日付型に変換して、Columnのデータを取り出す ... date = pd.to_datetime(df.index) series = df['Close'] # プロットする。 plt.figure(figsize=(6,4)); plt.plot_date(date, series, '-'); 上記では、インデックスを日付型に変換して、時系列にデータが並ぶように設定した後、日経平均の終値を取り出しグラフにプロットしている。その結果、出力されたグラフが下記のとおり。 ちょうど、80年代も終わろうとしているあたりから90年代のはじめにかけてピークを迎えているのが見てとれるだろう。いわゆるバブル期である。2009年ごろに底を打ち、その後徐々に上方基調になろうとしているように見えるが、本当にそうだろうか？ それはもっと多角的な統計解析を実行しないと、その判断はおそらく難しいと思われる。 このように python を使えば、思ったより簡単に情報の可視化が実行できることをわかって頂けたことだろうと思う。ここから先は、ぜひ、皆さんのセンスと実行力で掘り下げてほしいと思う。なお、今回、インストールを試みた anacondaパッケージには、統計分析、数学的処理に関するライブラリが標準で備わっているので、そのおもしろさをシンプルに体験することが可能だ。 まとめ 現在 python の最新版は、バージョン 3.7 及び 2.7 の2つの系統が存在している。どちらの選択肢をとればよいのか？ に関しては、現時点では 3.7 にすること。それ以上は、今後掘り下げた場合に必要に応じてメンテナンス体系を把握していけばよい。 pythonをインストールするにあたり、anacondaパッケージをとくに推奨する。理由は、python周辺の体系や文化になれるまで悩む箇所を極力減らすためだ。 pip install というコマンドは、anacondaパッケージに収録されていないライブラリを導入するための、いわゆるパッケージマネージャである。 今回の記事では、pythonのコードやセンテンスに関してほとんど説明をしていない。それは、即効性のあるコードをまず実行してみて結果を得てみる … ということを重視したためだ。今回のコードを徐々に編集しつつ疑問を持った時点で調べるほうが興味を維持しやすいと思われるし、とくに pythonは、いろいろな情報にあふれているので、可視化という観点で試してみて、いろいろ調べてみる、というアプローチをとったほうが手を動かしやすいだろう .. という判断でもある。 今回は、ここまで。 Best Regards;","link":"/blogger/2019/05/06/2019-05-1stweek/"},{"title":"ペアプロットで可視化、そして、正則化確認","text":"機械学習を学習するにあたって、まずはじめに直面する課題はおおむね iris だと思いますが、これは非常にシンプルな課題なので、今回はその内容を紹介してみたいと思います。しかし、いきなり機械学習に踏み込む前に統計的手法を用いて、最適な特徴量を選択し、その効果をアルゴリズムで確認する、というところまでを見たいと思います。 環境は、anaconda があるとベストです。anacondaの中の jupyter notebook をコードエディタ、確認用UIとして、機械学習の動作環境として scikit-learn を使用します。 今回の環境は … 以下のとおりです。グラフの描画で seaborn を使用してみようと思います。 123$ pip freeze&gt; scikit-learn==0.20.3&gt; seaborn==0.9.0 まずは、notebookを作成したら、irisをロードします。Notebook123In []:from sklearn.datasets import load_irisiris = load_iris() irisの構成を見る前に、簡単にirisの説明を書いておこうと思いますが、わかりやすく言えば植物のアヤメ科のことです。このアヤメ科には多くの属と種が存在しますが、irisのデータセットの中では、かなり小さくまとめられて非常に使いやすくなっています。つまり、いろいろな属性をもったアヤメ科の植物を、さまざまな観点で分類するような頭脳を作ろう、というのが、このiris課題の主眼です。 データセットの説明を参照してみます。 Notebook12In []:print(iris.DESCR) すると以下のような出力が得られます。 Notebook1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162Iris Plants Database====================Notes-----Data Set Characteristics: :Number of Instances: 150 (50 in each of three classes) :Number of Attributes: 4 numeric, predictive attributes and the class :Attribute Information: - sepal length in cm - sepal width in cm - petal length in cm - petal width in cm - class: - Iris-Setosa - Iris-Versicolour - Iris-Virginica :Summary Statistics: ============== ==== ==== ======= ===== ==================== Min Max Mean SD Class Correlation ============== ==== ==== ======= ===== ==================== sepal length: 4.3 7.9 5.84 0.83 0.7826 sepal width: 2.0 4.4 3.05 0.43 -0.4194 petal length: 1.0 6.9 3.76 1.76 0.9490 (high!) petal width: 0.1 2.5 1.20 0.76 0.9565 (high!) ============== ==== ==== ======= ===== ==================== :Missing Attribute Values: None :Class Distribution: 33.3% for each of 3 classes. :Creator: R.A. Fisher :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov) :Date: July, 1988This is a copy of UCI ML iris datasets.http://archive.ics.uci.edu/ml/datasets/IrisThe famous Iris database, first used by Sir R.A FisherThis is perhaps the best known database to be found in thepattern recognition literature. Fisher&apos;s paper is a classic in the field andis referenced frequently to this day. (See Duda &amp; Hart, for example.) Thedata set contains 3 classes of 50 instances each, where each class refers to atype of iris plant. One class is linearly separable from the other 2; thelatter are NOT linearly separable from each other.References---------- - Fisher,R.A. &quot;The use of multiple measurements in taxonomic problems&quot; Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to Mathematical Statistics&quot; (John Wiley, NY, 1950). - Duda,R.O., &amp; Hart,P.E. (1973) Pattern Classification and Scene Analysis. (Q327.D83) John Wiley &amp; Sons. ISBN 0-471-22361-1. See page 218. - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System Structure and Classification Rule for Recognition in Partially Exposed Environments&quot;. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. PAMI-2, No. 1, 67-71. - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;. IEEE Transactions on Information Theory, May 1972, 431-433. - See also: 1988 MLC Proceedings, 54-64. Cheeseman et al&quot;s AUTOCLASS II conceptual clustering system finds 3 classes in the data. - Many, many more ... 注目をしたいのは、Attribute Information と言う項目で、ここにはどのような属性が収録されているのか、ということが説明されています。ガクの長さと幅、花びらの長さと幅、そして class には Iris-Setosa, Iris-Versicolour, Iris-Virginica という3種類のアヤメが定義されています。この分類問題は、ガクや花びらの長さや大きさを学習して、どのアヤメの種類に分類されるのか？ といういわゆる 分類問題 にあたります。前述の属性は個体を表す情報としての 特徴量 とも呼ばれますが、その内容は以下のコードで確認できます。 Notebook12345In []:iris.data.shapeOut []:(150, 4) 特徴量は4種類。つまり、ガクの長さと幅、花びらの長さと幅の4つです。データ数は150点収録されているようです。アヤメの種別。classも確認してみます。 Notebook12345In []:print(iris.target_names)Out []:[&apos;setosa&apos; &apos;versicolor&apos; &apos;virginica&apos;] 3種類のアヤメを表現している出力が得られます。では、データセットの内容が実際にはどんな雰囲気なのかを確認してみます。これは、pandasのデータフレームにセットしてあげれば簡単に参照することができます。 Notebook12345In []:import pandas as pddf = pd.DataFrame(iris.data, columns=iris.feature_names)df.head(5) df.head(5)というコードはデータセットの先頭5件をピックアップして表示するという意味です。その結果、下のような出力が得られます。左から、ガクの長さ、幅、花びらの長さ、幅 と表示されています。 このデータセットの中では、classは 0, 1, 2 と表されているので、わかりやすいようにアヤメの種別を表す文字列に変換します。targetの列を判定して、それぞれ置き換えます。Notebook123456In []:df[&apos;target&apos;] = iris.targetdf.loc[df[&apos;target&apos;] == 0, &apos;target&apos;] = &quot;setosa&quot;df.loc[df[&apos;target&apos;] == 1, &apos;target&apos;] = &quot;versicolor&quot;df.loc[df[&apos;target&apos;] == 2, &apos;target&apos;] = &quot;virginica&quot;df.head(5)確認してみます。データセット全体の要約統計量も確認しておきます。 ここまでで準備が整いました。 今回の課題は、各特徴量を学習して、3種類のどのアヤメに分類したらよいのか？ という内容となるわけですが、ここにポイントとなるのは、どの特徴量をとれば正しく分類できるのかの見通しを立てないとなりません。簡単なデータであれば推測も成り立つかもしれませんが、仮に巨大なデータセットを前にしたときなどは、その方法では対応できません。そこで比較的手軽な方法として統計的な根拠を得るためにペアプロットを試してみます。コード自体はほとんどシンプルに書けます。まず seaborn が必要なことに注意します。 Notebook12345In []:import seaborn as sb%matplotlib inlinesb.pairplot(df, kind=&apos;reg&apos;, hue=&quot;target&quot;) このコードだけで各特徴量の組み合わせごとに散布図を出力できます。 特徴量の組み合わせを観察しますが、比較的分散が少ないので、どの特徴量を選択しても大差ないようにも見えます。 では、実際の分類を試してみますが、今回実行したいのは、作成したモデルの決定境界を観察してみることにポイントを置きたいと思います。ですので、正答率の評価というよりは、どのハイパーパラメータが実際に効いてくるのか、という点に着目してみようと思います。訓練データを作成します。本来は、ここでvalidation, testの単位に分割しますが、ここではチューニングの方向性の確認という視点でいきます。使用する特徴量は、ガクと花びらのそれぞれの長さを採用します。 Xに訓練データを投入し、yには教師データとしてアヤメを表す class を投入します。 Notebook123In []:X = iris.data[:, [0, 2]]y = iris.target データを可視化するための部品を作成しておきます。 Notebook123456789101112131415161718192021222324252627In []:import numpy as npimport matplotlib.pyplot as plt# グラフの設定h = .02 # step size in the meshx_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))def decision_boundary(clf, X, y, ax, title): clf.fit(X, y) # decision boundaryを描画します。 Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]) # 結果のプロット Z = Z.reshape(xx.shape) ax.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired) # 訓練データのプロット ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors=&apos;k&apos;, cmap=plt.cm.Paired) # グラフのラベル ax.set_title(title) ax.set_xlabel(&apos;sepal length&apos;) ax.set_ylabel(&apos;petal length&apos;) 採用するアルゴリズムはサポートベクターマシーンでいきたいと思います。法定境界の確認なので、よりわかりやすく非線形な分離を可視化したいと思います。 Notebook12345678910In []:from sklearn.svm import SVCfig, axes = plt.subplots(3, 3, figsize=(10, 10))for ax_row, C in zip(axes, [0.01, 1, 100]): for ax, gamma in zip(ax_row, [0.1, 1, 10]): title = &quot;C=%s, gamma=%s&quot;% (C, gamma) clf = SVC(C=C, gamma=gamma) decision_boundary(clf, X, y, ax, title) サポートベクターに与えるパラメータに対して、それぞれ 0.1, 1, 10 を試しています。正則化を表していますが、機械学習においては、偏ったデータに対して個別に対応してしまうと小さな誤差を許容してしまうモデルが出来上がってしまい、個別最適化されたようなゆがんだモデルが、適切な予測値を返せなくなります。この状態を過学習と言います。学習データの中の、ごく一部の例外的なデータに対して過度に対応したモデルということになります。そのために、機械学習では過学習になるのをふせぐために極端なデータに対してペナルティを与えますが、このことを正則化と言います。 さて、出力は …？ 右にいくほど、分類がきっちりしすぎています。一般的に学習データの件数が少ないと過学習に陥りやすいので、できるだけ汎化性能を高く保つ対策が必要になります。 今週気になったニュースde:code2019 基調講演今年もこの時期になりましたが、着々とAI拡充が進んでいる感じがあります。気になる人はオンデマンド配信で。 ロボットサービスの安全マネジメントに関する新規格を制定この分野では、まだ安全衛生に関する定義が追いついていなかったのですね …。 今週、最も気になったトピックではありました。","link":"/blogger/2019/06/07/2019-06-1stweek/"},{"title":"Cython と pure Python 実行速度比較","text":"今回は、Cython と pure Python の比較の実験をしてみたいと思う。Pyhonはとにかく遅いと言われる。型を持たないスクリプト言語なのだから仕方ないとは思うが、それでも遅いと言われる。そんな中でこの課題を解決しようとする文脈でよく登場するのが Cython ではあるが、では、どのくらいの差が出るのか？ そもそもパフォーマンスの違いは劇的なのか？ を実際に検証してみたいと思う。 そもそも Cython とはいかなるものなのか？ を簡単に説明しておきたいと思う。 Cythonは、低級言語である（C/C++）にコンパイル（つまりネイティブコードを生成して）パフォーマンスの課題に対して答えを出すというところに狙いがある。呼び出しは Python のメカニズムによるので、つまり、それはマジックコマンドを通じて、コンパイルされたコードが実行される、ということだ。しかしながら、ほとんど Pythonコードに遜色のない状態の記述から呼び出したり、あるいは、しっかりと型指定を定義した状態で実行したり、と、とくにパイソニックなライブラリとのコンビネーションを企てようとすると一筋縄ではいかない側面を当然持っている。 ここでは、その上澄みをとりつつも、ピュアなPythonとネイティブではこのくらいの差が出るのか、あるいは、そうでもないのか、という部分をちらっと垣間見てみたいと思う。 それでは、テスト環境を構築する。ふだん使用している環境には手を入れずに、テストをするだけの目的で環境を立ち上げて検証が終わればさっさと処分するのみの環境なので、ここから書くことはあまり本質的ではないので、先を急ぐ方は、もう少し後ろまで読み飛ばして大丈夫です。 今回のテストは このイメージ を使用して dockerコンテナを立ち上げる。このイメージは、Anacondaで構築されているので、コンテナを作成すればそのままJupyter Notebookをすぐに使用可能。 Quick Start コンテナで環境を作成では、Docker Hub よりイメージをダウンロードする。1$ docker pull jupyter/datascience-notebook コンテナを起動する前に同梱されている Python関係のバージョンをチェックする。1234567891011$ docker run --rm jupyter/datascience-notebook python --versionPython 3.7.3$ docker run --rm jupyter/datascience-notebook jupyter --version4.4.0docker run --rm --name test jupyter/datascience-notebook jupyter notebook --version5.7.8docker run --rm --name test jupyter/datascience-notebook cython --versionCython version 0.29.6 自身の環境ではこうなった。Cythonもちゃんと入っている。したがって、このコンテナを起動すればそのままテストが実行できる。では、起動する。 1$ docker run -it --rm -p 8888:8888 jupyter/datascience-notebook これでOK。ここで注意しないといけないのは、–rm コマンドを発行しているので、コンテナをシャットダウンしたら、すべて削除される。つまり、テスト結果もなくなるので、ご注意を。逆に言えば、コンテナを落とせばテスト環境もきれいに片付く、ということだ。起動後、ブラウザで localhost:8888 にアクセスすれば Jupyter Notebook が起動する。docker-machine を使用されてる方であれば、おそらく 192.168.99.100/101:8888 みたいなアドレスになると思う。Jupyter Notebookを開くことが出来たら トークンの入力を求められると思うので、ログを読みだす必要がある。以下のようなコマンドで標準出力にログが書き出されるので、そこからトークンを読み取って欲しい。 1$ docker logs &lt;コンテナID&gt; コンテナIDは、以下のコマンドで確認できる。1$ docker ps では、早速 notebookを新規作成して … 以下のコードを入力する。 Notebook1%load_ext Cython ここから4種類の条件を違えて、コードを記述してゆく。まずは、pure Pythonで記載したコード Notebook12345def pure_python(n): a, b = 0, 1 for i in range(n): a, b = a + b, a return a pure Python での実行速度を計測した結果は以下のとおり。 Notebook12%timeit pure_python(5000)519 µs ± 5.93 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 次に、Cythonで記載したコード Notebook1234567%%cython def cython(n): a, b = 0, 1 for i in range(n): a, b = a + b, a return a そして、実行結果は …Notebook12%timeit cython(5000)419 µs ± 1.58 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) かすかに速くなってはいるという感じ。次に、引数に型アノテーションを付与したCythonコード Notebook1234567%%cython def cython_typed_anotation(int n): a, b = 0, 1 for i in range(n): a, b = a + b, a return a 実行結果は …Notebook1%timeit cython_typed_anotation359 µs ± 977 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each) また、かすかに速くなっていることが確認できるが、このコードブロック単体ではそれほど大きな効果を実感できるというイメージではない。最後に、関数内の変数すべての型アノテーションを付与した CythonコードNotebook123456789%%cython def cython_alltyped_anotetion(int n): cdef int a,b,i a, b = 0, 1 for i in range(n): a, b = a + b, a return a 実行結果は …Notebook12.84 µs ± 71.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) ここにきて大きな変化があった。わかりにくいので結果を下記にまとめる。pure Python 519 µs ± 5.93 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)Cython 419 µs ± 1.58 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)Cython 引数に型指定 359 µs ± 977 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)Cython すべての引数に型指定 2.84 µs ± 71.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) ここまでやるか … という内容ではあるが、すべての引数に型指定をした場合のインパクトはかなり大きいということがわかった。可読性を犠牲にするのに加えて、あまりパイソニックな感じがしないコードになってしまうが、これはこれで効果があるということがデータとしてわかった。では、厳密に型指定を施したCythonコードとは他の条件、つまり、引数にのみ型指定をした場合と型指定をしない場合のCythonコードに関して効果は見込めないか？ というと、おそらく単体のコードブロックのみを使用するのであればほとんど意味はないと思われる。どのように使われる関数であるか？ という観点での踏み込みで判断すべきことだろう。Pythonには Numpy という優れたライブラリがあるので、これで達成できないようなあまり合理的ではないコードが、もしあった場合は、考える余地はあるかもしれない。 今度は、もう少し具体性のあるコードブロックを使ってその差を検証してみようと思う。画像解析をイメージして、2次元配列に対する離散畳み込みのフィルター処理で比較してみたいと思う。想定としては、画像を表現するNumpyの二次元配列と畳み込みのカーネルを引数で与える関数を書いて条件をふって比較する形だ。画像サイズは100X100、カーネルは5X5 の条件。 Numpyをimportしておく。Notebook1import numpy as np そして、まずは pure なコードブロックを想定した関数。Notebook123456789101112131415161718192021222324252627def pure_filter(f, g): vupper = img.shape[0] wupper = img.shape[1] supper = filter.shape[0] tupper = filter.shape[1] smidium = supper tmidium = tupper xupper = vupper + 2*smidium yupper = wupper + 2*tmidium # 出力画像を想定した配列 h = np.zeros([xupper, yupper], dtype=f.dtype) # 畳み込み処理 for x in range(xupper): for y in range(yupper): # filter の各ピクセルに対する加算 s_from = max(smidum - x, -smidum) s_to = min((xupper - x) - smidum, smidum + 1) t_from = max(tmidum - y, -tmidum) t_to = min((ymidum - y) - tmidum, tmidum + 1) value = 0 for s in range(s_from, s_to): for t in range(t_from, t_to): v = x - smidum + s w = y - tmidum + t value += filter[smidum - s, tmidum - t] * img[v, w] h[x, y] = value return h そして、実行してみる。Notebook1234N = 100img = np.arange(N*N, dtype=np.int).reshape((N,N))filter = np.arange(81, dtype=np.int).reshape((9, 9))%timeit -n2 -r3 pure_filer(img, filter) 結果は …Notebook1414 ms ± 1.57 ms per loop (mean ± std. dev. of 3 runs, 2 loops each) 今度は、Cythonのアノテーションを意識したコードブロックを書いて実行してみる。条件は同じ画像、同じカーネルフィルタの想定。Notebook123456789101112131415161718192021222324252627282930313233%%cythonimport numpy as npcimport numpy as npDTYPE = np.intctypedef np.int_t DTYPE_tdef cython_filter(np.ndarray img, np.ndarray filter): cdef int vupper = img.shape[0] cdef int wupper = img.shape[1] cdef int supper = filter.shape[0] cdef int tupper = filter.shape[1] cdef int smidium = supper // 2 cdef int tmidium = tupper // 2 cdef int xupper = vupper + 2*smidium cdef int yupper = wupper + 2*tmidium cdef np.ndarray h = np.zeros([xupper, yupper], dtype=DTYPE) cdef int x, y, s, t, v, w cdef int s_from, s_to, t_from, t_to cdef DTYPE_t value for x in range(xupper): for y in range(yupper): s_from = max(smidium - x, -smidium) s_to = min((xupper - x) - smidium, smidium + 1) t_from = max(tmidium - y, -tmidium) t_to = min((yupper - y) - tmidium, tmidium + 1) value = 0 for s in range(s_from, s_to): for t in range(t_from, t_to): v = x - smidium + s w = y - tmidium + t value += filter[smidium - s, tmidium - t] * img[v, w] h[x, y] = value return h 結果は …Notebook123456N = 100f = np.arange(N*N, dtype=np.int).reshape((N,N))g = np.arange(81, dtype=np.int).reshape((9, 9))%timeit -n2 -r3 cython_filter(f, g)372 ms ± 301 µs per loop (mean ± std. dev. of 3 runs, 2 loops each) 並べてみる。pure Python 414 ms ± 1.57 ms per loop (mean ± std. dev. of 3 runs, 2 loops each)Cython すべての型に型指定 372 ms ± 301 µs per loop (mean ± std. dev. of 3 runs, 2 loops each) あまり効果は出ていないということがわかった。とはいえ、かなり素直なコードであるのでこういう答えが出たが、アルゴリズムの工夫ではもう少し詰められるのかどうか … は、検討課題だと思われる。しかし、このぐらいであれば素直に OpenCV のほうがシンプルではあるだろう。 今週気になったニュースVisual Stuio 2019先月のニュースにはなってしまうが、正式版になりました。今回は、Github上のコードを学習した結果賢くなった IntelliCode と、ペアプログラミングを支援する Live Share が正式版になったということが大きな目玉ではあるが、地味なところでは、メモリの使用量をぐっと抑えて 1/4 にしたというところがある。 Google I/O 2019 Kotlinファースト 強化を表明この時期になると Google I/O ではあるが、現在、Android開発者の50％以上がKotlinユーザだそうだ。 Microsoft Build 2019 - WSL 2同じく5月の Microsoft Build ではあるが、個人的にもっともぐっときたのがこのアナウンスでした。Windows Subsystem for Linux 2 となり、Linuxシステムコールのフル互換をうたっています。しかも、正式に Docker対応をアナウンスしました。仮想マシーンを用意することが大きな壁になっていた感はありますが、これは Docker にチャレンジする大きな機会かもしれませんよ！ Best Regards;","link":"/blogger/2019/05/10/2019-05-2ndweek/"}],"tags":[{"name":"XG-X","slug":"XG-X","link":"/blogger/tags/XG-X/"},{"name":"jupyter","slug":"jupyter","link":"/blogger/tags/jupyter/"},{"name":"機械学習","slug":"機械学習","link":"/blogger/tags/機械学習/"},{"name":"Cython","slug":"Cython","link":"/blogger/tags/Cython/"},{"name":"Docker","slug":"Docker","link":"/blogger/tags/Docker/"}],"categories":[]}